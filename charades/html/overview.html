<H3>Charades Challenge 2017</H3>
<img src="https://s3-us-west-2.amazonaws.com/ai2-vision-challenge2017/action_recognition/logo.jpg" alt="">
<br>
<p> The Charades Challenge aims towards automatic understanding of daily activities, by providing realistic videos of people doing everyday activities.
                            The Charades dataset is collected for an unique insight into daily tasks such as drinking coffee, putting on shoes while sitting in a chair, or snuggling with a blanket on the couch while watching something on a laptop.
                            This enables computer vision algorithms to learn from real and diverse examples of our daily dynamic scenarios.
                            The challenge consists of two separate tracks: classification and localization track.
                            The <b>classification track</b> is to recognize all activity categories for given videos ('Activity Classification'), where multiple overlapping activities can occur in each video.
                            The <b>localization track</b> is to find the temporal locations of all activities in a video ('Activity Localization')
</p>
<H3>Track Information</H3> &nbsp;
<p>
This challenge is split between these two tracks, with separate leader boards and winners for each. Performance will be measured on:
</p>
<p>
    <b>Multi-label Video Classification Task:</b>
The task accepts submissions that use any available training data to train a model that predicts a score for 157 classes in each video. The performance of the algorithms is evaluated with mean average precision (mAP) across the videos.
</p>
<p>
    <b>Multi-label Action Localization Task:</b>
The task accepts submission that use any available training data to train a model that predicts a score for 157 classes for 25 equally spaced time-points in each video. The performance of the algorithms is evaluated with mean average precision (mAP) across all frames in all the videos.
</p>

